{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ed400f-6836-4e47-8461-25f266db52df",
   "metadata": {},
   "source": [
    "# Scraping Audi Data from PakWheels.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b74b1-748a-4389-bb9f-040c8ce7f166",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e421719a-a687-4361-a49b-61f7412fbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92e719-ade1-4110-86be-27b1453a4a29",
   "metadata": {},
   "source": [
    "## Method for printing logs in separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee884a0f-6180-491d-9c50-e8eadd51af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_progress(message):\n",
    "    with open('./logs/code_logs.txt','a') as file:\n",
    "        file.write(f\"{datetime.now()} : {message}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b7c8e-2b59-4266-b33a-d74870f34aec",
   "metadata": {},
   "source": [
    "## Method to extract urls of all audis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebc56edf-613c-4004-af04-342852fd11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_of_each_car(url):\n",
    "    try:\n",
    "        logging_progress('Intializing Extracting of URLS of each audi.')\n",
    "        urls = []\n",
    "        soup = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "        new_audis_lists = soup.find_all(class_=\"generic-car-widgets-container\")\n",
    "        for audi_container in new_audis_lists:\n",
    "            car_list = audi_container.find_all(class_='cards')\n",
    "            for car_container in car_list:\n",
    "                tag = car_container.find('a')\n",
    "                link = \"https://www.pakwheels.com\"+tag.get(\"href\")\n",
    "                urls.append(link)\n",
    "        logging_progress('URLS extraction completed.')\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        logging_progress(f\"Error occurred during url extracting!!!!!\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996d071-c7a9-4c4a-93ca-304849f80770",
   "metadata": {},
   "source": [
    "## Method to extract data of audis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2e1d9f-7353-4d9c-9860-b686c9be9662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_data(urls):\n",
    "    cars_data_list = []\n",
    "    logging_progress('Initializing Extracting of each audi data.')\n",
    "    for u in urls:\n",
    "        car_info_dict = {}\n",
    "        soup = BeautifulSoup(requests.get(u).content, 'html.parser')\n",
    "        heading_container = soup.find(class_='sect-heading-cont')\n",
    "        car_info_dict['Model'] = heading_container.find(class_='mb0').text.strip().replace('Specifications', '')\n",
    "        car_info_block = soup.find(id='model-detailed-specs')\n",
    "        car_data = car_info_block.find_all('td')\n",
    "        for i in range(0, len(car_data), 2):\n",
    "            car_info_dict[car_data[i].text.strip()] = car_data[i+1].text.strip()\n",
    "        cars_data_list.append(car_info_dict)  \n",
    "    logging_progress('Data extraction completed.')\n",
    "    return pd.DataFrame(cars_data_list)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1a5f4-8512-4129-8c7f-74d0d3becd5e",
   "metadata": {},
   "source": [
    "## Method to transform data(Deriving new column Fuel efficiency on the basis of mileage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e81e13d-83e6-4ee3-a439-8770c7ba128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    logging_progress('Initializing transforming data(including new column fuel effieciency according to mileage).')\n",
    "    mileage_bounds = df['Mileage'].str.extract(r'(\\d+)\\s*-\\s*(\\d+)')\n",
    "    mileage_bounds = mileage_bounds.astype(float)\n",
    "    df['Average_Mileage'] = mileage_bounds.mean(axis=1)\n",
    "    \n",
    "    def categorize_efficiency(mileage):\n",
    "        if mileage > 15:\n",
    "            return \"High Efficiency\"\n",
    "        elif 10 <= mileage < 15:\n",
    "            return \"Medium Efficiency\"\n",
    "        else:\n",
    "            return \"Low Efficiency\"\n",
    "    df['Fuel Efficiency'] = df['Average_Mileage'].apply(categorize_efficiency)\n",
    "    logging_progress('Data transformation completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd3b73-e0f6-48e8-a9bd-246580174065",
   "metadata": {},
   "source": [
    "## loading data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c3be14-5f02-4a3a-8793-27967d8c10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    logging_progress('Initializing Loading of transform data.')\n",
    "    df.to_csv('./output/Audi-data.csv')\n",
    "    logging_progress('Data loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01400046-48a4-4edb-9d25-cec0fb46c3ac",
   "metadata": {},
   "source": [
    "## Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52467e82-9ddd-4620-b14e-3ec104bca3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the base URL for extracting car data (Audi cars in this case)\n",
    "    url = 'https://www.pakwheels.com/new-cars/audi/'\n",
    "    # Extract URLs of individual car models from the main page\n",
    "    urls = extract_url_of_each_car(url)\n",
    "    # Scrape detailed specifications for each car using the extracted URLs\n",
    "    data = extract_data(urls)\n",
    "    # Transform the extracted data (e.g., categorize fuel efficiency, clean data, etc.)\n",
    "    transform_data(data)\n",
    "    # Load the transformed data into storage (e.g., save to CSV, database, etc.)\n",
    "    load_data(data)\n",
    "    logging_progress('ETL Process completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65068c83-501c-4216-a629-dacc40595e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
